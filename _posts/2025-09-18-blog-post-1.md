---
title: 'News Article Reading'
date: 2025-09-18
permalink: /posts/2025/09/blog-post-1/
tags:
  - case study
  - blog
  - ethics
  - twitter/x
  - elon musk
  - AI
  - grok
---

"What is going on with Twitter's AI under Elon Musk?"

**News Article reading:**  
['Improved Grok' News Article](https://techcrunch.com/2025/07/06/improved-grok-criticizes-democrats-and-hollywoods-jewish-executives/)


---

This article covers X (formerly Twitter)'s AI Grok, and Elon Musk boasting about it's improved model following an update. This article covers the "update"'s new, odd behavior, and the type of information this AI started spreading across the platform. 


Last year, I was taking a course where we could write just about anything we wanted as long as it could relate back to the course (This course was called Money & Magic). I had decided to make my essay on Elon Musk and the "fetish" of Billionaires in America. This essay started up just after the announcement of D.O.G.E, and the following chaos that the first month in office had brought. I did a lot of research about how he changed Twitter, and how dangerous his control over the platform could be. So when I saw this article, I figured it would tie in to a lot of the things I had to say when writing. 

It's immediately apparent when taking a look at Grok that this AI is incredibly harmful. The intention I feel from Elon Musk and the people working for Twitter is that they want Grok to be this "cool" sort of character. They want the AI to be used (obviously, why else would they make it), and it's a huge problem when they hard-code in the political ideology they want this thing to push. They want something to spread their biased ideas in one of the largest social platforms of all time. They buy this huge platform and spread misinformation with it. If that's not an ethical concern, I'm not really sure what is. 

As far as the stakeholders go in this article, I could identify:

Stakeholder: Users of the website

Role or Context: Use Twitter/X's AI to answer questions, or to use it to help understand posts made on the website. 
Ethical Concern: Potentially recieving and promoting false information that had been compiled by an AI on social media.

Stakeholder: Elon Musk

Role or Context: Twitter/X CEO, Affiliate of the Republican Party in the U.S., Self-proclaimed "attack dog" for Donald Trump.  
Ethical Concern: Using AI to push a political agenda to a massive crowd. Spreading false information and conspiracy theories though an easily accessible AI.

So linking this article back to discussions we've been having in my current CS course: we've been talking about ethical frameworks a lot. And through the lense of the frameworks we've been covering, I sort of came up with a few connections that can be made regarding the actions that the development team has/should have taken for developing Grok:

Utilitarianism:

Right Action: Creating a method of delivering brief, accurate information upon request. 

Wrong Action: Spreading traditionally antisemitic and transphobic rhetoric through a public platform. Generally posting conspiracies or misinformation about marginalized communities to push an ideology. 

Contractarianism:

Right Action: Fairness would entail unbiased, factual information to be delivered consistently. 

Wrong Action: A heavy bias towards one group over the other, as well as censoring information that doesn't agree with certain worldviews. 

---

Overall, the article was an interesting (if not slightly depressing) read. I think this made for a good introduction to doing blog posts. I'm writing this while revising, but it was nice using this article to test out the format. It something that was engaging and I felt like I had a lot of content without feeling the need to stall for a self-imposed "word count." 

The blog format is a welcome refresher to writing things out on a Google doc. This feels a lot less rigid than that, and in some ways I really appreciate that even if it's a little difficult in other areas. 

Anyway, main takeaway: I don't like Elon Musk. Shocking.