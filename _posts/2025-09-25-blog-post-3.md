---
title: 'Data-Driven Rule & Exceptions to the Rule'
date: 2025-09-25
permalink: /posts/2025/09/blog-post-3/
tags:
  - case study
  - blog
  - ethics
  - data-driven rule
  - AI
  - nuance
  - algorithms
---

Who is responsible for those who are forced to fall through the cracks?

**Case Study:**  
['"The Right to be an Exception to a Data-Driven Rule"](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)

---

This article discusses what data-driven rules are, and how they're potentially harmful. In particular, the study places an emphasis on the "exceptions" who are unfairly harmed by data-driven rules. 

So, what is a "data-driven rule?"

A data-driven rule is an algorithm made to make decisions based on the average answers it is given. Essentially, it is something made to save time by making judgements based on previous information. Exceptions are outliers to the "average answers" the data-driven rule is given. They fall through the cracks of the system, and become left behind. An exception isn't the same as an error: they still qualify, yet they are still denied by the algorithm based on incorrect judgement.

A key factor that distinguished data-driven rules from human decisions, is that data-driven decisions struggle to account for nuance. Humans may be able to determine nuance based on experience and outside factors, but a machine is incapable of that level of judgement. They're entirely reliant on established facts, and functioning outside of that scope is sort of beyond them. 

In an ideal world, individualism would allow for algorithms to make judgements with perfect accuracy. On the other hand, it may lead to some major privacy concerns for the user. Theres a constand trade-off that we experience all the time where we can have incredible feats through tech, but it's reliant on giving up our privacy to random third parties.  

Theres a reason that uncertainty is so valuable, and it's the same reason that machines struggle with it: Uncertainty allows space for nuance. Its one way to prevent making hasty, life-changing decisions where the outcome is hard to totally predict. It allows you to understand that there isn't enough knowledge to see how things will end up. AI wants to give an answer, and it will do anything it can to provide one. We've discussed before in class how LLMs like ChatGPT will go to the extent of lying to the user in order to answer a question. They don't know how to react to unknowns. 

So upon reading all of this, I want to bring up a new discussion: Do you think it's worth trying to refine a data-driven rule? Should we really be leaving it up to a non-living thing to make life-changing decisions? Is it worth the save in time?

--- 

Reflecting on news like this is always going to be a little depressing. I can't stop the hint of hopelessness I feel whenever I think about that fact so many people's lives are reliant on systems that don't really care about them. And now, instead of humans processing and denying requests for insurance, we make AI do it. We decided to cut out the middle man and just let the system dictate who does and doesn't get a credit card. To me, it just feels like letting a balloon go into the sky and watching where it ends up outside: you don't get to have input on where it lands. It'll crash when it crashes. 